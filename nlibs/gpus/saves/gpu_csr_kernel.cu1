#include "CSR.h"
#include <cuda.h>
#include <cuda_runtime.h>
#include <stdio.h>
//#include <cub/cub.cuh>
//using namespace cub;
//CachingDeviceAllocator  g_allocator;

template
<int WARP_SIZE, int WARPS>
__global__ void gpu_csr_spmm(const CSR A, const CSR B,
    const int *IC, int *JC, double* C,
    bool *xbs, double *xs, const int tsize) {
  int gthreadId = blockDim.x * blockIdx.x + threadIdx.x;
  int nWarps = blockDim.x / WARP_SIZE;
  int warpId = gthreadId / WARP_SIZE;
  int laneId = gthreadId % WARP_SIZE;

  int aColIt = A.rowPtr[warpId] + laneId;
  int aColEnd = A.rowPtr[warpId + 1];
  int colA = aColIt < aColEnd ? A.colInd[aColIt] : -1;
  double valA = aColIt < aColEnd ? A.values[aColIt] : 0.0;
  int k, end;
  __shared__ volatile int sColA[WARPS];
  __shared__ volatile double sValA[WARPS];
  bool* xb = xbs + tsize * warpId;
  double *x = x + tsize * warpId;
  for (k = 0, end = __popc(__ballot(aColIt < aColEnd)); k < end; ++k) {
    if (laneId == k) {
      sColA[warpId] = colA;
      sValA[warpId] = valA;
    }
    int bColIt = B.rowPtr[sColA[warpId]];
    int bColEnd = B.rowPtr[sColA[warpId] + 1];
    for (int bt = bColIt; bt < bColEnd; bt += tsize) {
      for (bColIt = bt + laneId; bColIt < bt + tsize; bColIt += WARP_SIZE) {
        int colB = bColIt < bColEnd ? B.colInd[bColIt] : -1;
        double valB = bColIt < bColEnd ? B.values[bColIt] : 0.0;
        if (xb[colB - bt] == false) {
          xb[colB - bt] = true;
          x[colB - bt] = sValA[warpId] * valB;
        } else {
          x[colB - bt] += sValA[warpId] * valB;
        }
        //printf("%d\t%d\t%lf\n", warpId, colB, sValA[warpId] * valB);
      }
      for (int t = laneId; t <  tsize; t += WARP_SIZE) {

      }
    }
  }
}

void gpu_CSR_SpMM(const CSR &dA, const CSR &dB, CSR &dC) {
    int nblocks = 2;
    //gpu_csr_spmm<32, 512/32><<<1, 512>>>(dA, dB);
    cudaDeviceSynchronize();
    return;
}
